{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import pandas as pd\n",
    "from feast import FeatureStore\n",
    "from feast.dqm.profilers.ge_profiler import ge_profiler\n",
    "from great_expectations.core.expectation_suite import ExpectationSuite\n",
    "from great_expectations.dataset import PandasDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tigra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\feast\\feature_store.py:900: RuntimeWarning: Retrieving datasets is an experimental feature. This API is unstable and it could and most probably will be changed in the future. We do not guarantee that future changes will maintain backward compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Getting our feature store\n",
    "store = FeatureStore(repo_path=\"driver_stats/\")\n",
    "\n",
    "# Getting a saved dataset\n",
    "dataset = store.get_saved_dataset(name=\"driver_stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tolerance value for the mean\n",
    "DELTA = 0.1\n",
    "\n",
    "# Creating a profiler function\n",
    "@ge_profiler\n",
    "def stats_profiler(ds: PandasDataset) -> ExpectationSuite:\n",
    "    # DEFINING MINIMUM AND MAXIMUM\n",
    "    # EXPECTED VALUES\n",
    "\n",
    "    # Getting min and max values for avg_daily_trips\n",
    "    observed_min = ds[\"avg_daily_trips\"].min()\n",
    "    observed_max = ds[\"avg_daily_trips\"].max()\n",
    "\n",
    "    # Setting the expected min and max values\n",
    "    ds.expect_column_values_to_be_between(\n",
    "        column=\"avg_daily_trips\",\n",
    "        mostly=0.99,\n",
    "        min_value=observed_min,\n",
    "        max_value=observed_max       \n",
    "    )\n",
    "\n",
    "    # DEFINING EXPECTED AVERAGE\n",
    "\n",
    "    # Getting the average of avg_daily_trips\n",
    "    observed_mean = ds[\"avg_daily_trips\"].mean()\n",
    "    \n",
    "    # Setting the expected range\n",
    "    ds.expect_column_mean_to_be_between(\n",
    "        column=\"avg_daily_trips\",        \n",
    "        min_value=observed_mean * (1 - DELTA),\n",
    "        max_value=observed_mean * (1 + DELTA)\n",
    "    )\n",
    "\n",
    "    # Retrieving comparison results\n",
    "    return ds.get_expectation_suite(discard_failed_expectations=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/23/2022 04:10:05 PM INFO:\t2 expectation(s) included in expectation_suite. result_format settings filtered.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<GEProfile with expectations: [\n",
       "  {\n",
       "    \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "    \"kwargs\": {\n",
       "      \"column\": \"avg_daily_trips\",\n",
       "      \"mostly\": 0.99,\n",
       "      \"min_value\": 2,\n",
       "      \"max_value\": 998\n",
       "    },\n",
       "    \"meta\": {}\n",
       "  },\n",
       "  {\n",
       "    \"expectation_type\": \"expect_column_mean_to_be_between\",\n",
       "    \"kwargs\": {\n",
       "      \"column\": \"avg_daily_trips\",\n",
       "      \"min_value\": 435.62050632911394,\n",
       "      \"max_value\": 532.4250632911393\n",
       "    },\n",
       "    \"meta\": {}\n",
       "  }\n",
       "]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the expectation function\n",
    "dataset.get_profile(profiler=stats_profiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the dataset as a reference for validation\n",
    "validation_reference = dataset.as_reference(profiler=stats_profiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an entity DataFrame with timestamps\n",
    "timestamps = pd.date_range(\n",
    "    start=\"2021-09-05\",    \n",
    "    end=\"2021-09-06\",     \n",
    "    freq='H').to_frame(name=\"event_timestamp\", index=False)\n",
    "\n",
    "# Creating patient IDs for the entity DataFrame\n",
    "driver_ids = pd.DataFrame(data=[1001, 1002, 1003, 1004, 1005], \n",
    "                          columns=[\"driver_id\"])\n",
    "\n",
    "# Create the cartersian product of our timestamps and entities \n",
    "entity_df = timestamps.merge(right=driver_ids, \n",
    "                             how=\"cross\")\n",
    "\n",
    "# Getting the indicated historical features\n",
    "# and joining them with our entity DataFrame\n",
    "historical_features = store.get_historical_features(\n",
    "    entity_df=entity_df,\n",
    "    features=[\n",
    "        \"driver_stats_fv:conv_rate\",\n",
    "        \"driver_stats_fv:acc_rate\",\n",
    "        \"driver_stats_fv:avg_daily_trips\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tigra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\feast\\infra\\offline_stores\\offline_store.py:89: RuntimeWarning: Dataset validation is an experimental feature. This API is unstable and it could and most probably will be changed in the future. We do not guarantee that future changes will maintain backward compatibility.\n",
      "  warnings.warn(\n",
      "03/23/2022 04:10:05 PM INFO:\t2 expectation(s) included in expectation_suite. result_format settings filtered.\n",
      "03/23/2022 04:10:05 PM INFO:Validating data_asset_name None with expectation_suite_name default\n"
     ]
    },
    {
     "ename": "ValidationFailed",
     "evalue": "[\n  {\n    \"result\": {\n      \"element_count\": 125,\n      \"missing_count\": 0,\n      \"missing_percent\": 0.0,\n      \"unexpected_count\": 2,\n      \"unexpected_percent\": 1.6,\n      \"unexpected_percent_total\": 1.6,\n      \"unexpected_percent_nonmissing\": 1.6,\n      \"partial_unexpected_list\": [\n        0,\n        1\n      ],\n      \"partial_unexpected_index_list\": [\n        61,\n        73\n      ],\n      \"partial_unexpected_counts\": [\n        {\n          \"value\": 0,\n          \"count\": 1\n        },\n        {\n          \"value\": 1,\n          \"count\": 1\n        }\n      ],\n      \"unexpected_list\": [\n        0,\n        1\n      ],\n      \"unexpected_index_list\": [\n        61,\n        73\n      ]\n    },\n    \"exception_info\": {\n      \"raised_exception\": false,\n      \"exception_message\": null,\n      \"exception_traceback\": null\n    },\n    \"expectation_config\": {\n      \"expectation_type\": \"expect_column_values_to_be_between\",\n      \"kwargs\": {\n        \"column\": \"avg_daily_trips\",\n        \"mostly\": 0.99,\n        \"min_value\": 2,\n        \"max_value\": 998,\n        \"result_format\": \"COMPLETE\"\n      },\n      \"meta\": {}\n    },\n    \"success\": false,\n    \"meta\": {}\n  }\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationFailed\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13652/1329615607.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Converting the RetrievalJob to a DataFrame and validating it against our reference dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistorical_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_reference\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_reference\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\feast\\infra\\offline_stores\\offline_store.py\u001b[0m in \u001b[0;36mto_df\u001b[1;34m(self, validation_reference)\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[0mvalidation_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_reference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvalidation_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_success\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValidationFailed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfeatures_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValidationFailed\u001b[0m: [\n  {\n    \"result\": {\n      \"element_count\": 125,\n      \"missing_count\": 0,\n      \"missing_percent\": 0.0,\n      \"unexpected_count\": 2,\n      \"unexpected_percent\": 1.6,\n      \"unexpected_percent_total\": 1.6,\n      \"unexpected_percent_nonmissing\": 1.6,\n      \"partial_unexpected_list\": [\n        0,\n        1\n      ],\n      \"partial_unexpected_index_list\": [\n        61,\n        73\n      ],\n      \"partial_unexpected_counts\": [\n        {\n          \"value\": 0,\n          \"count\": 1\n        },\n        {\n          \"value\": 1,\n          \"count\": 1\n        }\n      ],\n      \"unexpected_list\": [\n        0,\n        1\n      ],\n      \"unexpected_index_list\": [\n        61,\n        73\n      ]\n    },\n    \"exception_info\": {\n      \"raised_exception\": false,\n      \"exception_message\": null,\n      \"exception_traceback\": null\n    },\n    \"expectation_config\": {\n      \"expectation_type\": \"expect_column_values_to_be_between\",\n      \"kwargs\": {\n        \"column\": \"avg_daily_trips\",\n        \"mostly\": 0.99,\n        \"min_value\": 2,\n        \"max_value\": 998,\n        \"result_format\": \"COMPLETE\"\n      },\n      \"meta\": {}\n    },\n    \"success\": false,\n    \"meta\": {}\n  }\n]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Converting the RetrievalJob to a DataFrame and validating it against our reference dataset\n",
    "_ = historical_features.to_df(validation_reference=validation_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an entity DataFrame with timestamps\n",
    "timestamps = pd.date_range(\n",
    "    start=\"2021-09-05\",    \n",
    "    end=\"2021-09-15\",     \n",
    "    freq='H').to_frame(name=\"event_timestamp\", index=False)\n",
    "\n",
    "# Creating patient IDs for the entity DataFrame\n",
    "driver_ids = pd.DataFrame(data=[1001, 1002, 1003, 1004, 1005], \n",
    "                          columns=[\"driver_id\"])\n",
    "\n",
    "# Create the cartersian product of our timestamps and entities \n",
    "entity_df = timestamps.merge(right=driver_ids, \n",
    "                             how=\"cross\")\n",
    "\n",
    "# Getting the indicated historical features\n",
    "# and joining them with our entity DataFrame\n",
    "historical_features = store.get_historical_features(\n",
    "    entity_df=entity_df,\n",
    "    features=[\n",
    "        \"driver_stats_fv:conv_rate\",\n",
    "        \"driver_stats_fv:acc_rate\",\n",
    "        \"driver_stats_fv:avg_daily_trips\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tigra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\feast\\infra\\offline_stores\\offline_store.py:89: RuntimeWarning: Dataset validation is an experimental feature. This API is unstable and it could and most probably will be changed in the future. We do not guarantee that future changes will maintain backward compatibility.\n",
      "  warnings.warn(\n",
      "03/23/2022 04:10:24 PM INFO:\t2 expectation(s) included in expectation_suite. result_format settings filtered.\n",
      "03/23/2022 04:10:24 PM INFO:Validating data_asset_name None with expectation_suite_name default\n"
     ]
    }
   ],
   "source": [
    "# Converting the RetrievalJob to a DataFrame and validating it against our reference dataset\n",
    "_ = historical_features.to_df(validation_reference=validation_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tigra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\feast\\feature_store.py:900: RuntimeWarning: Retrieving datasets is an experimental feature. This API is unstable and it could and most probably will be changed in the future. We do not guarantee that future changes will maintain backward compatibility.\n",
      "  warnings.warn(\n",
      "03/23/2022 04:10:26 PM INFO:\t2 expectation(s) included in expectation_suite. result_format settings filtered.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<GEProfile with expectations: [\n",
       "  {\n",
       "    \"expectation_type\": \"expect_column_values_to_be_between\",\n",
       "    \"kwargs\": {\n",
       "      \"column\": \"avg_daily_trips\",\n",
       "      \"mostly\": 0.99,\n",
       "      \"min_value\": 2,\n",
       "      \"max_value\": 998\n",
       "    },\n",
       "    \"meta\": {}\n",
       "  },\n",
       "  {\n",
       "    \"expectation_type\": \"expect_column_mean_to_be_between\",\n",
       "    \"kwargs\": {\n",
       "      \"column\": \"avg_daily_trips\",\n",
       "      \"min_value\": 435.62050632911394,\n",
       "      \"max_value\": 532.4250632911393\n",
       "    },\n",
       "    \"meta\": {}\n",
       "  }\n",
       "]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting a saved dataset\n",
    "dataset_1001 = store.get_saved_dataset(name='driver_stats_1001')\n",
    "\n",
    "# Checking the expectation function\n",
    "dataset_1001.get_profile(profiler=stats_profiler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an entity DataFrame with timestamps\n",
    "timestamps = pd.date_range(\n",
    "    start=\"2021-09-05\",    \n",
    "    end=\"2021-09-15\",     \n",
    "    freq='H').to_frame(name=\"event_timestamp\", index=False)\n",
    "\n",
    "# Creating patient IDs for the entity DataFrame\n",
    "driver_ids = pd.DataFrame([1001], columns=[\"driver_id\"])\n",
    "\n",
    "# Create the cartersian product of our timestamps and entities \n",
    "entity_df = timestamps.merge(right=driver_ids, how=\"cross\")\n",
    "\n",
    "# Getting the indicated historical features\n",
    "# and joining them with our entity DataFrame\n",
    "historical_features = store.get_historical_features(\n",
    "    entity_df=entity_df,\n",
    "    features=[\n",
    "        \"driver_stats_fv:conv_rate\",\n",
    "        \"driver_stats_fv:acc_rate\",\n",
    "        \"driver_stats_fv:avg_daily_trips\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tigra\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\feast\\infra\\offline_stores\\offline_store.py:89: RuntimeWarning: Dataset validation is an experimental feature. This API is unstable and it could and most probably will be changed in the future. We do not guarantee that future changes will maintain backward compatibility.\n",
      "  warnings.warn(\n",
      "03/23/2022 04:10:29 PM INFO:\t2 expectation(s) included in expectation_suite. result_format settings filtered.\n",
      "03/23/2022 04:10:29 PM INFO:Validating data_asset_name None with expectation_suite_name default\n"
     ]
    }
   ],
   "source": [
    "# Converting the RetrievalJob to a DataFrame and validating it against our reference dataset\n",
    "_ = historical_features.to_df(validation_reference=validation_reference)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0281ae4893e10b52c4d5b801530748bd8cbe731f1c41bfa8f327e88220bd1102"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
